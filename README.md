# Framework free neural network implementation

This project involved implementing and testing a neural network from scratch, without relying on popular deep learning frameworks like Keras, TensorFlow, or PyTorch. The main objectives and accomplishments of the project are as follows:

1. Implementation: The neural network was developed entirely from scratch, without utilizing any existing deep learning frameworks. This approach allowed for a comprehensive understanding of the fundamental principles underlying deep learning algorithms.

2. Computation Graph: A computation graph was built from scratch, including its forward and backward traversal in the program. This involved manually defining the network's layers, connections, and activation functions, without relying on dynamic configurations. By constructing the computation graph, a deep understanding of the underlying architecture and operations of the neural network was gained.

3. Training Procedure: A robust training procedure was created to effectively optimize the model weights. This included designing a suitable loss function to quantify the discrepancy between predicted and target values. An evaluation function was also implemented to assess the performance of the trained model on validation or test data. Stochastic gradient descent (SGD) algorithm was employed as the optimization technique, with adjustable learning rate and decay parameters to fine-tune the model's convergence.
